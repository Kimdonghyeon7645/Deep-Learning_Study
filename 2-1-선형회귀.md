# 2-1. 선형회귀

### 1. 선형회귀의 정의, 종류

선형회귀(linear regression) 란, 이름처럼 선형의 예측선을 그려서 다음의 들어올 값을 예측선에 따라서 예측하는 것이다.

간단하게 ```학생들의 성적이 다르다.```를, 
```학생들의 성적이 [ ]에 따라 다르다.```라고도 이야기할 수 있는데, 
여기서 [ ] 안에 들어가는 내용을 정보라고 한다. 
그래서 정보 중에서 공부시간을 예로 든다면, ```학생들의 성적이 [공부시간]에 따라 다르다.```라고 할 수 있을 것이다. 그러면, 공부시간에 따라서 성적이 다르게 나오므로, 학생들의 공부시간을 가지고 성적도 예측할 수 있을 것이다.

이것을 함수로 나타낸다면, 우리가 아는 일차함수로도 표현할 수 있을 것이다. 어떻게 하냐면, 성적과 같은 결과 값을 변하게 하는 ‘정보’를 x로 하고, 이 **정보(x)**에 따라서 변하는 성적과 같은 **결과를 y**라고 할 수 있다.

여기서 이 x와 y를 수학적인 표현으로 바꾸면, x는 독립적으로 변하는 **독립변수(x)** 라고 하며, y는 독립변수에 따라서 종속되어서 변하므로, **종속변수(y)** 라 한다.

여기서 선형회귀는 독립변수(x)로 종속변수(y)를 예측하는 작업이다. 
그리고 독립변수(x)가 하나뿐이라면 **단순 선형 회귀(simple linear regreession)**, 반대로 여러 개라면 **다중 선형 회귀(multiple linear regression)** 이라고 한다.

---

단순 선형 회귀는 우리가 쉽게 아는 y = ax + b 라는 일차함수의 그래프로 그려지는 직선이다.  
이 선으로, x값에 따른 y값에 대한 오차가 적은(정확한) 일직선을 그리는 것이 예측의 관건이 된다.   
이 y = ax + b 의 정확한 일차함수 직선을 만들려면, **“최소제곱법”** 을 이용하면 되는데, 이것이 회귀분석의 표준 방식이다. 

### 2. 최소 제곱법

