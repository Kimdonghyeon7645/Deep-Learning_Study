# 3-1. 퍼셉트론

### 1. 퍼셉트론의 정의

지금까지 배웠던, 선형회귀, 로지스틱 회귀에서 () 같은 식을 마치 인간의 뇌의 뉴런처럼 그림으로 그려서 표현한 것이, 사실 퍼셉트론이다.

![image](https://user-images.githubusercontent.com/48408417/86527673-5b2d4f00-bedc-11ea-9324-1d819ac0487e.png)

**퍼셉트론** 은 인공신경망의 한 종류로, 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)에 의해 고안되었다 라는 역사가 있는데,  
너무 어렵게 볼 필요 없이, 지금까지 배운 함수식을 그림으로 표현하고 약간의 용어를 바꾼 것이다.   
그리고 이 **“퍼셉트론(perceptron)”** 이 인공신경망, 오차역전파의 발전을 거쳐서 오늘날의 딥러닝에 이르게 된다.

뇌의 신경에서도 가장 중요한 기본단위가 뉴런이듯이, 인공 신경망(줄여서 신경망)의 가장 중요한 기본단위가 바로 퍼셉트론이며, 뉴런처럼 입력(x)을 전달(y)하는 역할을 수행하는 가장 기본적인 요소들이다. 

이제 퍼셉트론에서는 y= ax + b라는 a는 기울기고, b는 절편이라는 용어를 딥러닝 스럽게 바꿔 부르는데, a는 **w(weight), 가중치** 라고 하며, b는 **b(bias: 편향, 선입견), 바이어스** 라고 한다.   
그리고 값(x)과 가중치(w)들의 곱을 모두 더한 후에 바이어스(b)를 추가로 더한 값,

![image](https://user-images.githubusercontent.com/48408417/86527696-8f087480-bedc-11ea-9457-548f9ae6e52d.png)

을 **가중합(weighted sum)** 이란 용어로 부르게 된다.   
마지막으로, 가중합을 가지고 참 아니면 거짓을 판단해서 출력하는 함수를 통틀어서 **활성화 함수(activation function)** 라고 부르게 된다.   
(대표적인 활성화 함수는 로지스틱 회귀에서 배운 시그모이드 함수가 있다.)

---

이렇게 퍼셉트론 하나하나를 인간에 뇌에 있는 수많은 뉴런처럼, 수많은 퍼셉트론으로 신경망을 만들면 흡사 뇌같은 구조를 만들 수 있을 거라 예상했지만,   
퍼셉트론의 한계가 발견되면서 그 예상은 깨지게 된다. 바로 XOR문제다.

