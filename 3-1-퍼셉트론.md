# 3-1. 퍼셉트론

### 1. 퍼셉트론의 정의

지금까지 배웠던, 선형회귀, 로지스틱 회귀에서 () 같은 식을 마치 인간의 뇌의 뉴런처럼 그림으로 그려서 표현한 것이, 사실 퍼셉트론이다.

![image](https://user-images.githubusercontent.com/48408417/86527673-5b2d4f00-bedc-11ea-9324-1d819ac0487e.png)

**퍼셉트론** 은 인공신경망의 한 종류로, 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)에 의해 고안되었다 라는 역사가 있는데,  
너무 어렵게 볼 필요 없이, 지금까지 배운 함수식을 그림으로 표현하고 약간의 용어를 바꾼 것이다.   
그리고 이 **“퍼셉트론(perceptron)”** 이 인공신경망, 오차역전파의 발전을 거쳐서 오늘날의 딥러닝에 이르게 된다.

뇌의 신경에서도 가장 중요한 기본단위가 뉴런이듯이, 인공 신경망(줄여서 신경망)의 가장 중요한 기본단위가 바로 퍼셉트론이며, 뉴런처럼 입력(x)을 전달(y)하는 역할을 수행하는 가장 기본적인 요소들이다. 

이제 퍼셉트론에서는 y= ax + b라는 a는 기울기고, b는 절편이라는 용어를 딥러닝 스럽게 바꿔 부르는데, a는 **w(weight), 가중치** 라고 하며, b는 **b(bias: 편향, 선입견), 바이어스** 라고 한다.   
그리고 값(x)과 가중치(w)들의 곱을 모두 더한 후에 바이어스(b)를 추가로 더한 값,

![image](https://user-images.githubusercontent.com/48408417/86527696-8f087480-bedc-11ea-9457-548f9ae6e52d.png)

을 **가중합(weighted sum)** 이란 용어로 부르게 된다.   
마지막으로, 가중합을 가지고 참 아니면 거짓을 판단해서 출력하는 함수를 통틀어서 **활성화 함수(activation function)** 라고 부르게 된다.   
(대표적인 활성화 함수는 로지스틱 회귀에서 배운 시그모이드 함수가 있다.)

---

이렇게 퍼셉트론 하나하나를 인간에 뇌에 있는 수많은 뉴런처럼, 수많은 퍼셉트론으로 신경망을 만들면 흡사 뇌같은 구조를 만들 수 있을 거라 예상했지만,   
퍼셉트론의 한계가 발견되면서 그 예상은 깨지게 된다. 바로 XOR문제다.

### 2. 퍼셉트론의 한계(XOR문제)와 극복

![image](https://user-images.githubusercontent.com/48408417/86527731-db53b480-bedc-11ea-9aaa-6d7c92954e12.png)

XOR문제는 배타적 OR문제로, 기존의 OR연산과 AND연산은 쉽게 예측선을 그릴 수 있지만, XOR은 도무지 하나의 직선으로 예측선을 그릴 수 없는 문제가 발생한다.


이것이 발견되면서, 활발했던 퍼셉트론의 연구는 정체가 되었고, 이 인공신경망과 관련된 연구도 한동안 침체기를 겪게 되었다...   
이 문제를 해결하기엔, 다층 퍼셉트론이 구현되어야 한다만, 퍼셉트론의 한계를 증명한 마빈 민스키는 이것이 불가능하다 했다.   
그렇게 인공신경망의 연구 침체기가 몇 십년간 이어지는데, 인공지능의 첫 번째 겨울이라고 하는 시기가 이때다.   
하지만, 1986년 오차 역전파 알고리즘으로 다층 퍼셉트론을 학습시키는데 성공했다는 소식으로 그 시기는 깨지게 된다.

그렇다면 **다층 퍼셉트론(multilayer perceptron)과 오차 역전파 알고리즘** 은 무엇일까?  
다층 퍼셉트론은 말 그대로 층이 여러개인 퍼셉트론이며, 오차 역전파 알고리즘은, 오차를 구해서 가중치를 수정하는 알고리즘이다.  
근데 역전파라는 알고리즘이 붙은 이유는, 오차를 구해 수정해나가는 과정이 역으로 수행되기 때문이다.

그러면, 과연 층만 여러 개인 퍼셉트론으로, 어떻게 단일 퍼셉트론에서도 해결하지 못한 XOR 문제를 해결했을까?  
그 해답은 2차원 평면으로 직선을 그리는 것이 아니라, 평면을 왜곡해서 직선을 그리는 것에 있다.  
